{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Currently broken. Needs to be converted into python scripts utilising functions as part of custom packages."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "import ntpath\r\n",
    "import shutil\r\n",
    "import sys\r\n",
    "import argparse\r\n",
    "from datetime import datetime\r\n",
    "import random\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import cv2\r\n",
    "from PIL import Image, ImageChops, ImageDraw, ImageOps, ImageFilter, ImageStat, ImageEnhance \r\n",
    "from skimage import io, color, exposure\r\n",
    "#import imutils\r\n",
    "import matplotlib\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import glob\r\n",
    "import math\r\n",
    "#import blend_modes\r\n",
    "\r\n",
    "from damage import no_damage, remove_quadrant, remove_hole, bullet_holes, graffiti, bend_vertical\r\n",
    "from utils import load_paths, load_files, scale_image, create_alpha\r\n",
    "\r\n",
    "original = True # Whether we are using the original exposure_manipulation code or not"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create the output directories if they don't exist already\r\n",
    "base_dir = \"Traffic_Signs_Templates\"\r\n",
    "input_dir = os.path.join(base_dir, \"1_Input_Images\")\r\n",
    "output_dir = os.path.join(base_dir, \"2_Processed_Images\")\r\n",
    "if (not os.path.exists(base_dir)):\r\n",
    "    os.mkdir(base_dir)\r\n",
    "if (not os.path.exists(output_dir)):\r\n",
    "    os.mkdir(output_dir)\r\n",
    "\r\n",
    "# Rescale images and make white backgrounds transparent\r\n",
    "paths = load_files(input_dir)\r\n",
    "for path in paths:\r\n",
    "    img = scale_image(path) # Rescale the image\r\n",
    "\r\n",
    "    # Remove the extension and save as a png\r\n",
    "    _, filename = ntpath.split(path)\r\n",
    "    name, _ = filename.rsplit('.', 1)\r\n",
    "    save_path = os.path.join(output_dir, name) + \".png\"\r\n",
    "    img.save(save_path)\r\n",
    "\r\n",
    "    delete_background(save_path, save_path) # Overwrite the newly rescaled image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Used for SGTSD\r\n",
    "#TODO: Use cmd line parameters for damage_types?\r\n",
    "damage_types = [\"ORIGINAL\", \"QUADRANT\", \"BIG_HOLE\", \"HOLES\", \"YELLOW\", #TODO: Remove damage_types and fix downstream dependencies\r\n",
    "                 \"GRAFFITI\", \"BEND\", \"GREY\"]\r\n",
    "labels_dir = \"SGTSD/Labels\"\r\n",
    "\r\n",
    "def damage_image(image_path, output_dir):\r\n",
    "    \"\"\"Applies all the different types of damage to the imported image, saving each one\"\"\"\r\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\r\n",
    "    img = img.astype('uint8')\r\n",
    "    \r\n",
    "    # Create file writing info: filename, class number, output directory, and labels directory\r\n",
    "    _, filename = ntpath.split(image_path)  # Remove parent directories to retrieve the image filename\r\n",
    "    class_num, _ = filename.rsplit('.', 1)  # Remove extension to get the sign/class number\r\n",
    "\r\n",
    "    output_path = os.path.join(output_dir, class_num)\r\n",
    "    # Create the output directory if it doesn't exist already\r\n",
    "    if (not os.path.exists(output_path)):\r\n",
    "        os.makedirs(output_path)\r\n",
    "\r\n",
    "    # Create the labels directory for this sign if it doesn't exist already\r\n",
    "    if (not os.path.exists(os.path.join(labels_dir, class_num))):\r\n",
    "        os.makedirs(os.path.join(labels_dir, class_num))\r\n",
    "    # text_base = os.path.join(labels_dir, class_num, class_num + \"_\")  # The base filename for the label files\r\n",
    "    # ii = 0  # Class number that is appended to the end of base filename\r\n",
    "\r\n",
    "\r\n",
    "    # ORIGINAL UNDAMAGED\r\n",
    "    dmg, att = no_damage(img)\r\n",
    "    cv2.imwrite(os.path.join(output_path, class_num + \".png\"), dmg)\r\n",
    "    \r\n",
    "    # QUADRANT\r\n",
    "    dmg1, att = remove_quadrant(img)\r\n",
    "    cv2.imwrite(os.path.join(output_path, class_num + \"_\" + att[\"damage\"] + \".png\"), dmg1)\r\n",
    "    \r\n",
    "    # BIG HOLE\r\n",
    "    dmg2, att = remove_hole(img)\r\n",
    "    cv2.imwrite(os.path.join(output_path, class_num + \"_\" + att[\"damage\"] + \".png\"), dmg2)\r\n",
    "    \r\n",
    "    # RANDOMISED BULLET HOLES\r\n",
    "    dmg3, att = bullet_holes(img)\r\n",
    "    cv2.imwrite(os.path.join(output_path, class_num + \"_\" + att[\"damage\"] + \".png\"), dmg3)\r\n",
    "    \r\n",
    "    # TINTED YELLOW\r\n",
    "    # yellow = np.zeros((height,width,ch), dtype=np.uint8)\r\n",
    "    # yellow[:,:] = (0,210,210,255)\r\n",
    "    # dmg4 = cv2.bitwise_and(img, yellow)\r\n",
    "    # # TODO: Use quadrant pixel difference ratio or some other damage metric for labelling?\r\n",
    "    # cv2.imwrite(os.path.join(output_path, class_num + damage_types[4] + \".png\"), dmg4)\r\n",
    "    \r\n",
    "    # GRAFFITI\r\n",
    "    dmgs, attrs = graffiti(img, color=(0,0,0))\r\n",
    "    for ii in range(len(dmgs)):\r\n",
    "        cv2.imwrite(os.path.join(output_path, class_num + \"_\" + attrs[ii][\"damage\"] + \"_\" + str(attrs[ii][\"ratio\"]) + \".png\"), dmgs[ii])\r\n",
    "    \r\n",
    "    # BEND\r\n",
    "    dmgs, attrs = bend_vertical(img)\r\n",
    "    for ii in range(len(dmgs)):\r\n",
    "        cv2.imwrite(os.path.join(output_path, class_num + \"_\" + attrs[ii][\"damage\"] + \"_\" + attrs[ii][\"tag\"] + \".png\"), dmgs[ii])\r\n",
    "    \r\n",
    "    # GREY\r\n",
    "    # dmg7 = cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY)   # Convert to greyscale\r\n",
    "    # # Threshold the image to get a uniform saturation\r\n",
    "    # _, dmg7 = cv2.threshold(dmg7, 100, 255, cv2.THRESH_BINARY)\r\n",
    "    # cv2.convertScaleAbs(dmg7, dmg7, alpha=1, beta=200)  # No change to contrast, scale brightness\r\n",
    "    # dmg7 = cv2.cvtColor(dmg7, cv2.COLOR_GRAY2BGRA)   # Convert back to BGRA to add back the alpha channel\r\n",
    "    # dmg7[:,:,3] = alpha_ch\r\n",
    "    # cv2.imwrite(os.path.join(output_path, class_num + damage_types[7] + \".png\"), dmg7)\r\n",
    "    # TODO: Test with exposure_manipulation()\r\n",
    "    # TODO: Write values to file\r\n",
    "    \r\n",
    "    # TODO: CRACKS (thin crack lines across the sign?)\r\n",
    "    # TODO: MISSING SECTIONS (missing polygon sections on edges of sign?)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create damaged signs using the images with backgrounds removed\r\n",
    "input_path = os.path.join(\"Traffic_Signs_Templates\", \"2_Processed_Images\")\r\n",
    "output_dir = os.path.join(\"Traffic_Signs_Templates\", \"3_Damaged_Images\")\r\n",
    "\r\n",
    "# Remove any old output and recreate the output directory\r\n",
    "if os.path.exists(output_dir):\r\n",
    "    shutil.rmtree(output_dir)\r\n",
    "os.mkdir(output_dir)\r\n",
    "\r\n",
    "for image_path in load_files(input_path):\r\n",
    "    damage_image(image_path, output_dir)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def add_pole(filename, color):\r\n",
    "    \"\"\"Adds a pole to the imported sign\"\"\"\r\n",
    "    img = cv.imread(filename, cv.IMREAD_UNCHANGED)\r\n",
    "    # Retrieve image dimentions and calculate the new height\r\n",
    "    height, width, _ = img.shape  # Discard channel\r\n",
    "    new_height = height * 3\r\n",
    "\r\n",
    "    # Create a new blank image with dtype=uint8 (to hold numbers 0-255)\r\n",
    "    # Initialise values to 0 so that the extended image is fully transparent\r\n",
    "    new_img = np.zeros((new_height, width, 4), dtype=np.uint8)\r\n",
    "    # Copy over the original image onto the top portion\r\n",
    "    new_img[0:height, :] = img\r\n",
    "\r\n",
    "    # Calculate coordinates\r\n",
    "    midpt = width // 2\r\n",
    "    offset = width // 40\r\n",
    "    x1, x2 = midpt - offset, midpt + offset\r\n",
    "    y1, y2 = height, new_height\r\n",
    "    # Draw the pole\r\n",
    "    cv.rectangle(new_img, (x1, y1), (x2, y2), color, cv.FILLED)\r\n",
    "\r\n",
    "    # Colour any transparent pixels between the sign and the rectangle\r\n",
    "    lim = 50  # Max alpha value for the pixel to be considered \"transparent\"\r\n",
    "    margin = int(round( height * 0.9 ))  # Loop over bottom 10% of the sign\r\n",
    "    for y in range(margin, height):\r\n",
    "        for x in range(x1, x2+1):  # Loop to x2 inclusive\r\n",
    "            if new_img[y,x,3] < lim:\r\n",
    "                new_img[y,x] = color\r\n",
    "\r\n",
    "    return new_img"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def img_transform(image_path, output_path):\r\n",
    "    \"\"\"Creates and saves different angles of the imported image\"\"\"\r\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\r\n",
    "    height,width,_ = img.shape\r\n",
    "\r\n",
    "    dst = []\r\n",
    "    #0 FORWARD FACING\r\n",
    "    dst.append( img )\r\n",
    "\r\n",
    "    #1 EAST FACING\r\n",
    "    pts1 = np.float32( [[width/10,height/10], [width/2,height/10], [width/10,height/2]] )\r\n",
    "    pts2 = np.float32( [[width/5,height/5], [width/2,height/8], [width/5,height/1.8]] )\r\n",
    "    M = cv2.getAffineTransform(pts1,pts2)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "    \r\n",
    "    #2 NORTH-WEST FACING\r\n",
    "    pts3 = np.float32( [[width*9/10,height/10], [width/2,height/10], [width*9/10,height/2]] )\r\n",
    "    pts4 = np.float32( [[width*9/10,height/5], [width/2,height/8], [width*9/10,height/1.8]] )\r\n",
    "    M = cv2.getAffineTransform(pts3,pts4)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "    \r\n",
    "    #3 LEFT TILTED FORWARD FACING\r\n",
    "    pts5 = np.float32( [[width/10,height/10], [width/2,height/10], [width/10,height/2]] )\r\n",
    "    pts6 = np.float32( [[width/12,height/6], [width/2.1,height/8], [width/10,height/1.8]] )\r\n",
    "    M = cv2.getAffineTransform(pts5,pts6)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "    \r\n",
    "    #4 RIGHT TILTED FORWARD FACING\r\n",
    "    pts7 = np.float32( [[width*9/10,height/10], [width/2,height/10], [width*9/10,height/2]] )\r\n",
    "    pts8 = np.float32( [[width*10/12,height/6], [width/2.2,height/8], [width*8.4/10,height/1.8]] )\r\n",
    "    M = cv2.getAffineTransform(pts7,pts8)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "    \r\n",
    "    #5 WEST FACING\r\n",
    "    pts9  = np.float32( [[width/10,height/10], [width/2,height/10], [width*9/10,height/2]] )\r\n",
    "    pts10 = np.float32( [[width/9.95,height/10], [width/2.05,height/9.95], [width*9/10,height/2.05]] )\r\n",
    "    M = cv2.getAffineTransform(pts9,pts10)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "    \r\n",
    "    #6 RIGHT TILTED FORWARD FACING\r\n",
    "    pts11 = np.float32( [[width*9/10,height/10], [width/2,height/10], [width*9/10,height/2]] )\r\n",
    "    pts12 = np.float32( [[width*9/10,height/10], [width/2,height/9], [width*8.95/10,height/2.05]] )\r\n",
    "    M = cv2.getAffineTransform(pts11,pts12)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "    \r\n",
    "    #7 FORWARD FACING W/ DISTORTION\r\n",
    "    pts13 = np.float32( [[width/10,height/10], [width/2,height/10], [width*9/10,height/2]] )\r\n",
    "    pts14 = np.float32( [[width/9.8,height/9.8], [width/2,height/9.8], [width*8.8/10,height/2.05]] )\r\n",
    "    M = cv2.getAffineTransform(pts13,pts14)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "    \r\n",
    "    #8 FORWARD FACING W/ DISTORTION 2\r\n",
    "    pts15 = np.float32( [[width/10,height/10], [width/2,height/10], [width*9/10,height/2]] )\r\n",
    "    pts16 = np.float32( [[width/11,height/10], [width/2.1,height/10], [width*8.5/10,height/1.95]] )\r\n",
    "    M = cv2.getAffineTransform(pts15,pts16)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "    \r\n",
    "    #9 FORWARD FACING W/ DISTORTION 3\r\n",
    "    pts17 = np.float32( [[width/10,height/10], [width/2,height/10], [width*9/10,height/2]] )\r\n",
    "    pts18 = np.float32( [[width/11,height/11], [width/2.1,height/10], [width*10/11,height/1.95]] )\r\n",
    "    M = cv2.getAffineTransform(pts17,pts18)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "    \r\n",
    "    #10 FORWARD FACING W/ DISTORTION 4\r\n",
    "    pts19 = np.float32( [[width*9.5/10,height/10], [width/2,height/10], [width*9/10,height/2]] )\r\n",
    "    pts20 = np.float32( [[width*9.35/10,height/9.99], [width/2.05,height/9.95], [width*9.05/10,height/2.03]] )\r\n",
    "    M = cv2.getAffineTransform(pts19,pts20)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "    \r\n",
    "    #11 FORWARD FACING W/ DISTORTION 5\r\n",
    "    pts21 = np.float32( [[width*9.5/10,height/10], [width/2,height/10], [width*9/10,height/2]] )\r\n",
    "    pts22 = np.float32( [[width*9.65/10,height/9.95], [width/1.95,height/9.95], [width*9.1/10,height/2.02]] )\r\n",
    "    M = cv2.getAffineTransform(pts21,pts22)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "    \r\n",
    "    #12 FORWARD FACING W/ DISTORTION 6\r\n",
    "    pts23 = np.float32( [[width*9.25/10,height/10], [width/2,height/10], [width*9/10,height/2]] )\r\n",
    "    pts24 = np.float32( [[width*9.55/10,height/9.85], [width/1.9,height/10], [width*9.3/10,height/2.04]] )\r\n",
    "    M = cv2.getAffineTransform(pts23,pts24)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "    \r\n",
    "    #13 SHRINK 1\r\n",
    "    pts25 = np.float32( [[width*9/10,height/10], [width/2,height/10], [width*9/10,height/2]] )\r\n",
    "    pts26 = np.float32( [[width*8/10,height/10], [width*1.34/3,height/10.5], [width*8.24/10,height/2.5]] )\r\n",
    "    M = cv2.getAffineTransform(pts25,pts26)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "    \r\n",
    "    #14 SHRINK 2\r\n",
    "    pts27 = np.float32( [[width*9/10,height/10], [width/2,height/10], [width*9/10,height/2]] )\r\n",
    "    pts28 = np.float32( [[width*8.5/10,height*3.1/10], [width/2,height*3/10], [width*8.44/10,height*1.55/2.5]] )\r\n",
    "    M = cv2.getAffineTransform(pts27,pts28)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "    \r\n",
    "    #15 FORWARD FACING W/ DISTORTION 7\r\n",
    "    pts29 = np.float32( [[width*9/10,height/10], [width/2,height/10], [width*9/10,height/2]] )\r\n",
    "    pts30 = np.float32( [[width*8.85/10,height/9.3], [width/1.9,height/10.5], [width*8.8/10,height/2.11]] )\r\n",
    "    M = cv2.getAffineTransform(pts29,pts30)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "    \r\n",
    "    #16 FORWARD FACING W/ DISTORTION 8\r\n",
    "    pts31 = np.float32( [[width*9/10,height/10], [width/2,height/10], [width*9/10,height/2]] )\r\n",
    "    pts32 = np.float32( [[width*8.75/10,height/9.1], [width/1.95,height/8], [width*8.5/10,height/2.05]] )\r\n",
    "    M = cv2.getAffineTransform(pts31,pts32)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "    \r\n",
    "    #17 FORWARD FACING W/ DISTORTION 9\r\n",
    "    pts33 = np.float32( [[width*9/10,height/10], [width/2,height/10], [width*9/10,height/2]] )\r\n",
    "    pts34 = np.float32( [[width*8.75/10,height/9.1], [width/1.95,height/9], [width*8.5/10,height/2.2]] )\r\n",
    "    M = cv2.getAffineTransform(pts33,pts34)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "    \r\n",
    "    #18 FORWARD FACING W/ DISTORTION 10\r\n",
    "    pts35 = np.float32( [[width*9/10,height/10], [width/2,height/10], [width*9/10,height/2]] )\r\n",
    "    pts36 = np.float32( [[width*8.75/10,height/8], [width/1.95,height/8], [width*8.75/10,height/2]] )\r\n",
    "    M = cv2.getAffineTransform(pts35,pts36)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "    \r\n",
    "    #19 FORWARD FACING W/ DISTORTION 11\r\n",
    "    pts37 = np.float32( [[width*9/10,height/10], [width/2,height/10], [width*9/10,height/2]] )\r\n",
    "    pts38 = np.float32( [[width*8.8/10,height/7], [width/1.95,height/7], [width*8.8/10,height/2]] )\r\n",
    "    M = cv2.getAffineTransform(pts37,pts38)\r\n",
    "    dst.append( cv2.warpAffine(img,M,(width,height)) )\r\n",
    "\r\n",
    "    # Retrieve the filename to save as\r\n",
    "    _,tail = ntpath.split(image_path)  # Filename of the image, parent directories removed\r\n",
    "    title,_ = tail.rsplit('.', 1)      # Discard extension\r\n",
    "    \r\n",
    "    # Save the transformed images\r\n",
    "    for ii in range(1, len(dst)):\r\n",
    "        save_path = os.path.join(output_path, title)\r\n",
    "        if not os.path.exists(save_path):\r\n",
    "            os.makedirs(save_path)\r\n",
    "        cv2.imwrite(os.path.join(save_path, str(ii) + \".png\"), dst[ii])\r\n",
    "#    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "input_path = os.path.join(\"Traffic_Signs_Templates\", \"3_Damaged_Images\")\r\n",
    "output_dir = os.path.join(\"Traffic_Signs_Templates\", \"4_Transformed_Images\")\r\n",
    "\r\n",
    "# Loop through each folder in the input directory\r\n",
    "for folder_path in load_paths(input_path):\r\n",
    "    # Retrieve the sign number to create a directory\r\n",
    "    _,number = os.path.split(folder_path)\r\n",
    "    save_dir = os.path.join(output_dir, number)\r\n",
    "    \r\n",
    "    for image_path in load_files(folder_path):\r\n",
    "        img_transform(image_path, save_dir)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def to_png(directory):\r\n",
    "    \"\"\"Convert all files in 'directory' to PNG images\"\"\"\r\n",
    "    for files in load_paths(directory):\r\n",
    "        title, extension = files.split('.')\r\n",
    "        img = Image.open(files).convert('RGBA')\r\n",
    "        if (not extension == \"png\"):\r\n",
    "            os.remove(files)\r\n",
    "        img.save(title + \".png\")"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from PIL import ImageFile\r\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\r\n",
    "\r\n",
    "for bg_folders in load_paths(\"Backgrounds\"):\r\n",
    "    to_png(bg_folders)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def find_image_exposure(paths, channels):\r\n",
    "    exposures = []\r\n",
    "    for image_path in paths:\r\n",
    "        img_grey = Image.open(image_path).convert('LA')  # Greyscale with alpha\r\n",
    "        img_rgba = Image.open(image_path)\r\n",
    "        \r\n",
    "        stat1 = ImageStat.Stat(img_grey)\r\n",
    "        # Average pixel brighness\r\n",
    "        avg = stat1.mean[0]\r\n",
    "        # RMS pixel brighness\r\n",
    "        rms = stat1.rms[0]\r\n",
    "        \r\n",
    "        stat2 = ImageStat.Stat(img_rgba)\r\n",
    "        # Consider the number of channels\r\n",
    "        # Background may have RGB while traffic sign has RGBA\r\n",
    "        if (channels == 3):\r\n",
    "            # Average pixels preceived brightness\r\n",
    "            r,g,b = stat2.mean\r\n",
    "            avg_perceived = math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2))\r\n",
    "            # RMS pixels perceived brightness\r\n",
    "            r,g,b = stat2.rms\r\n",
    "            rms_perceived = math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2))\r\n",
    "        else:\r\n",
    "            # Average pixels preceived brightness\r\n",
    "            r,g,b,a = stat2.mean\r\n",
    "            avg_perceived = math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2))\r\n",
    "            # RMS pixels perceived brightness\r\n",
    "            r,g,b,a = stat2.rms\r\n",
    "            rms_perceived = math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2)) \r\n",
    "\r\n",
    "        exposures.append( [image_path,avg,rms,avg_perceived,rms_perceived] )\r\n",
    "\r\n",
    "    return exposures     "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def exposure_manipulation(signs_paths, backgrounds_paths):\r\n",
    "    background_exposures = find_image_exposure(background_paths, 4)\r\n",
    "    signs_exposures = find_image_exposure(signs_paths, 4)\r\n",
    "    \r\n",
    "    for ii in range(0,len(background_paths)):\r\n",
    "        print(\"Processed: \" + str(float(ii) / float(len(background_paths)) * 100) + \" %\")\r\n",
    "        \r\n",
    "        img = Image.open(background_exposures[ii][0])\r\n",
    "\r\n",
    "        for sign_path in signs_paths:        \r\n",
    "            dirc, sub, el = dir_split(background_exposures[ii][0])\r\n",
    "            title, extension = el.rsplit('.', 1)\r\n",
    "\r\n",
    "            parent_dir, sub_dir, folder, folder2, element = dir_split(sign_path)\r\n",
    "            head, tail = element.rsplit('.', 1)\r\n",
    "\r\n",
    "            \r\n",
    "            ###   ORIGINAL EXPOSURE IMPLEMENTATION   ###\r\n",
    "            brightness_avrg = 1.0\r\n",
    "            brightness_rms = 1.0\r\n",
    "            brightness_avrg_perceived = 1.0\r\n",
    "            brightness_rms_perceived = 1.0\r\n",
    "            brightness_avrg2 = 1.0\r\n",
    "            brightness_rms2 = 1.0\r\n",
    "\r\n",
    "            # abs(desired_brightness - actual_brightness) / abs(brightness_float_value) = ratio\r\n",
    "            avrg_ratio = 11.0159464507\r\n",
    "\r\n",
    "            rms_ratio = 8.30320014372\r\n",
    "\r\n",
    "            percieved_avrg_ratio = 3.85546373056\r\n",
    "\r\n",
    "            percieved_rms_ratio = 35.6344530649\r\n",
    "\r\n",
    "            avrg2_ratio = 1.20354549572\r\n",
    "\r\n",
    "            rms2_ratio = 40.1209106864\r\n",
    "\r\n",
    "            peak1 = Image.open(sign_path).convert('LA')\r\n",
    "            peak2 = Image.open(sign_path).convert('RGBA')\r\n",
    "\r\n",
    "            stat = ImageStat.Stat(peak1)\r\n",
    "            avrg = stat.mean[0]\r\n",
    "            rms = stat.rms[0]\r\n",
    "\r\n",
    "            \r\n",
    "            ### IMAGE MANIPULATION MAIN CODE STARTS ###\r\n",
    "\r\n",
    "            # MINIMISE MARGIN BASED ON AVERAGE FOR TWO CHANNEL BRIGNESS VARIATION\r\n",
    "            margin = abs(avrg - float(background_exposures[ii][1]))\r\n",
    "            \r\n",
    "            brightness_avrg = margin / avrg_ratio \r\n",
    "            \r\n",
    "            enhancer = ImageEnhance.Brightness(peak2)\r\n",
    "            avrg_bright = enhancer.enhance(brightness_avrg)\r\n",
    "            stat = ImageStat.Stat(avrg_bright)\r\n",
    "            avrg = stat.mean[0]\r\n",
    "\r\n",
    "            \r\n",
    "            # MINIMISE MARGIN BASED ON ROOT MEAN SQUARE FOR TWO CHANNEL BRIGNESS VARIATION\r\n",
    "            margin = abs(rms - float(background_exposures[ii][2]))\r\n",
    "\r\n",
    "            brightness_rms = margin / rms_ratio \r\n",
    "            \r\n",
    "            enhancer = ImageEnhance.Brightness(peak2)\r\n",
    "            rms_bright = enhancer.enhance(brightness_rms)\r\n",
    "            stat = ImageStat.Stat(rms_bright)\r\n",
    "            rms = stat.rms[0]\r\n",
    "\r\n",
    "            \r\n",
    "            # MINIMISE MARGIN BASED ON AVERAGE FOR RGBA (\"PERCEIVED BRIGHNESS\")\r\n",
    "            # REFERENCE FOR ALGORITHM USED: http://alienryderflex.com/hsp.html\r\n",
    "            stat2 = ImageStat.Stat(peak2)\r\n",
    "            r, g, b, a = stat2.mean\r\n",
    "            avrg_perceived = math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2))\r\n",
    "            margin = abs(avrg_perceived - float(background_exposures[ii][3]))\r\n",
    "            \r\n",
    "            brightness_avrg_perceived = margin / percieved_avrg_ratio \r\n",
    "            \r\n",
    "            enhancer = ImageEnhance.Brightness(peak2)\r\n",
    "            avrg_bright_perceived = enhancer.enhance(brightness_avrg_perceived)\r\n",
    "            stat2 = ImageStat.Stat(avrg_bright_perceived)\r\n",
    "            r, g ,b, a = stat2.mean\r\n",
    "            avrg_perceived = math.sqrt(0.241 * (r**2) + 0.691 * (g**2) + 0.068 * (b**2))        \r\n",
    "\r\n",
    "\r\n",
    "            # MINIMISE MARGIN BASED ON RMS FOR RGBA (\"PERCEIVED BRIGHNESS\")\r\n",
    "            # REFERENCE FOR ALGORITHM USED: http://alienryderflex.com/hsp.html\r\n",
    "            r, g, b, a = stat2.rms\r\n",
    "            rms_perceived = math.sqrt(0.241 * (r**2) + 0.691 * (g**2) + 0.068 * (b**2))\r\n",
    "\r\n",
    "            margin = abs(rms_perceived - float(background_exposures[ii][4]))\r\n",
    "\r\n",
    "            brightness_rms_perceived = margin / percieved_rms_ratio \r\n",
    "\r\n",
    "            enhancer = ImageEnhance.Brightness(peak2)\r\n",
    "            rms_bright_perceived = enhancer.enhance(brightness_rms_perceived)\r\n",
    "            stat2 = ImageStat.Stat(rms_bright_perceived)\r\n",
    "            r, g, b, a = stat2.rms\r\n",
    "            rms_perceived = math.sqrt(0.241 * (r**2) + 0.691 * (g**2) + 0.068 * (b**2))        \r\n",
    "\r\n",
    "            \r\n",
    "            stat3 = ImageStat.Stat(peak2)\r\n",
    "            avrg2 = stat3.mean[0]\r\n",
    "            rms2 = stat3.rms[0]\r\n",
    "\r\n",
    "            \"\"\"\r\n",
    "            #FUSION OF THE TWO AVERAGING METHODS\r\n",
    "            margin = abs(avrg2-float(background_exposures[ii][1]))\r\n",
    "            brightness_avrg2 = margin/avrg2_ratio \r\n",
    "            enhancer = ImageEnhance.Brightness(peak2)\r\n",
    "            avrg_bright2 = enhancer.enhance(brightness_avrg2)\r\n",
    "            stat3 = ImageStat.Stat(avrg_bright2)\r\n",
    "            avrg2 = stat3.mean[0]       \r\n",
    "            \"\"\"\r\n",
    "            \r\n",
    "            \r\n",
    "            \"\"\"\r\n",
    "            #FUSION OF THE TWO RMS METHODS\r\n",
    "            margin = abs(rms2-float(background_exposures[ii][2]))\r\n",
    "            brightness_rms2 = margin/rms2_ratio \r\n",
    "            enhancer = ImageEnhance.Brightness(peak2)\r\n",
    "            rms_bright2 = enhancer.enhance(brightness_rms2)\r\n",
    "            stat3 = ImageStat.Stat(rms_bright2)\r\n",
    "            rms2 = stat3.rms[0]\r\n",
    "            \"\"\"\r\n",
    "            \r\n",
    "            avrg_bright = avrg_bright.resize((150,150), Image.ANTIALIAS)\r\n",
    "            rms_bright = rms_bright.resize((150,150), Image.ANTIALIAS)\r\n",
    "            avrg_bright_perceived = avrg_bright_perceived.resize((150,150), Image.ANTIALIAS)\r\n",
    "            rms_bright_perceived = rms_bright_perceived.resize((150,150), Image.ANTIALIAS)\r\n",
    "            # avrg_bright2 = avrg_bright2.resize((150,150), Image.ANTIALIAS)\r\n",
    "            # rms_bright2 = rms_bright2.resize((150,150), Image.ANTIALIAS)\r\n",
    "\r\n",
    "            \r\n",
    "            exp_dir = \"Traffic_Signs_Exposure_Manipulation\"\r\n",
    "            avrg_bright.save(os.path.join(exp_dir,sub,title,\"SIGN_\"+folder,folder2,head+\"_AVERAGE.\"+tail))\r\n",
    "            rms_bright.save(os.path.join(exp_dir,sub,title,\"SIGN_\"+folder,folder2,head+\"_RMS.\"+tail))\r\n",
    "            avrg_bright_perceived.save(os.path.join(exp_dir,sub,title,\"SIGN_\"+folder,folder2,head+\"_AVERAGE_PERCEIVED.\"+tail))\r\n",
    "            rms_bright_perceived.save(os.path.join(exp_dir,sub,title,\"SIGN_\"+folder,folder2,head+\"_RMS_PERCEIVED.\"+tail))\r\n",
    "            # avrg_bright2.save(os.path.join(exp_dir,sub,title,\"SIGN_\"+folder,folder2,head+\"_AVERAGE2.\"+tail))\r\n",
    "            # rms_bright2.save(os.path.join(exp_dir,sub,title,\"SIGN_\"+folder,folder2,head+\"_RMS2.\"+tail))\r\n",
    "    \r\n",
    "    print(\"Processed: \" + str(100) + \" %\")\r\n",
    "    print(\"Process was successful\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def fade_manipulation(signs_paths, backgrounds_paths):\r\n",
    "    background_exposures = find_image_exposure(background_paths, 4)\r\n",
    "    signs_exposures = find_image_exposure(signs_paths, 4)\r\n",
    "    \r\n",
    "    print(\"Processed: 0.0 %\")\r\n",
    "    ii = 0\r\n",
    "    prev = 0\r\n",
    "    for sign_path in signs_paths:\r\n",
    "        progress = float(ii) / float(len(signs_paths)) * 100\r\n",
    "        if progress >= prev + 5: #Prevent spamming of progress prints\r\n",
    "            prev = prev + 5\r\n",
    "            print(\"Processed: \" + str(progress) + \" %\")\r\n",
    "\r\n",
    "        dirc, sub, el = dir_split(background_exposures[0][0])\r\n",
    "        title, extension = el.split('.')\r\n",
    "\r\n",
    "        parent_dir, sub_dir, folder, folder2, element = dir_split(sign_path)\r\n",
    "        head, tail = element.split('.')\r\n",
    "\r\n",
    "        img = cv2.imread(sign_path, cv2.IMREAD_UNCHANGED)\r\n",
    "\r\n",
    "\r\n",
    "        ###   GRADUAL FADE IMPLEMENTATION   ###\r\n",
    "        # Retrieve alpha data from original image\r\n",
    "        splitImg = cv2.split(img)\r\n",
    "        if len(splitImg) == 4:\r\n",
    "            alphaData = splitImg[3]\r\n",
    "\r\n",
    "        for jj in range(0,5):\r\n",
    "            dmg6 = img.copy()\r\n",
    "            alpha = 1 - (jj * 0.19)\r\n",
    "            beta = (jj + 1) * 40\r\n",
    "            if jj > 0:\r\n",
    "                cv2.convertScaleAbs(img, dmg6, alpha, beta) # Scale the contrast and brightness\r\n",
    "                dmg6[:, :, 3] = alphaData\r\n",
    "\r\n",
    "            dmg6 = cv2.resize(dmg6, (150,150))\r\n",
    "            fad_dir = \"Traffic_Signs_Fade_Manipulation\"\r\n",
    "            cv2.imwrite(os.path.join(fad_dir,\"SIGN_\"+folder,folder2,head+\"_FADE-\"+str(jj)+\".\"+tail), dmg6)\r\n",
    "        ii = ii + 1\r\n",
    "    \r\n",
    "    \r\n",
    "    print(\"Processed: \" + str(100) + \" %\")\r\n",
    "    print(\"Process was successful\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bg_dir = \"Backgrounds\"\r\n",
    "transform_dir = os.path.join(\"Traffic_Signs_Templates\", \"4_Transformed_Images\")\r\n",
    "\r\n",
    "for dirs in load_paths(bg_dir):\r\n",
    "    sep = os.sep  # Directory separator: '/' or '\\'\r\n",
    "\r\n",
    "    if original is True:\r\n",
    "        for background in load_paths(dirs):\r\n",
    "            iniitial, subd, element = dir_split(background)\r\n",
    "            title, extension = element.split('.')\r\n",
    "\r\n",
    "            for signp in load_paths(transform_dir):\r\n",
    "                for sign in load_paths(signp):\r\n",
    "                    d,s,f,e = dir_split(sign)  # Eg. s = 4_Transformed_Images, f = 9, e = 9_BOTTOM_HOLE\r\n",
    "\r\n",
    "                    exp_dir = \"Traffic_Signs_Exposure_Manipulation\" + sep\r\n",
    "                    if (not os.path.exists(exp_dir + subd + sep + title + sep + \"SIGN_\" + f + sep + e)):\r\n",
    "                        os.makedirs(exp_dir + subd + sep + title + sep + \"SIGN_\" + f + sep + e)\r\n",
    "    else:\r\n",
    "        for signp in load_paths(transform_dir):\r\n",
    "            for sign in load_paths(signp):\r\n",
    "                d,s,f,e = dir_split(sign)\r\n",
    "\r\n",
    "                fade_dir = \"Traffic_Signs_Fade_Manipulation\" + sep\r\n",
    "                if (not os.path.exists(fade_dir + \"SIGN_\" + f + sep + e)):\r\n",
    "                    os.makedirs(fade_dir + \"SIGN_\" + f + sep + e)\r\n",
    "\r\n",
    "signs_paths = []\r\n",
    "for p in load_paths(transform_dir):\r\n",
    "    for d in load_paths(p):\r\n",
    "        signs_paths += load_paths(d)\r\n",
    "\r\n",
    "background_paths = []  # Load the paths of the background images into a single list\r\n",
    "for subfolder in load_paths(bg_dir):\r\n",
    "    background_paths += load_paths(subfolder)\r\n",
    "\r\n",
    "if original is True:\r\n",
    "    exposure_manipulation(signs_paths, background_paths)\r\n",
    "else:\r\n",
    "    fade_manipulation(signs_paths, background_paths)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true,
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def avrg_pixel_rgb(image, chanels):\r\n",
    "    stat = ImageStat.Stat(image)\r\n",
    "    if (chanels == 4):\r\n",
    "        r,g,b,a = stat.rms\r\n",
    "    else:\r\n",
    "        r,g,b = stat.rms\r\n",
    "    \r\n",
    "    return [r,g,b]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def find_bw_images(directory):\r\n",
    "    images = []\r\n",
    "    for sign in load_paths(directory):\r\n",
    "        for damage in load_paths(sign):\r\n",
    "            img = Image.open(damage).convert('RGBA')\r\n",
    "            rgb = avrg_pixel_rgb(img, 4)\r\n",
    "            rg = abs(rgb[0] - rgb[1])\r\n",
    "            rb = abs(rgb[0] - rgb[2])\r\n",
    "            gb = abs(rgb[1] - rgb[2])\r\n",
    "            \r\n",
    "            temp = dir_split(damage)\r\n",
    "            list = temp[-1].split('.')\r\n",
    "            if len(list) == 2:\r\n",
    "                head = list[0]\r\n",
    "            else:\r\n",
    "                head = list[0] + '.' + list[1]\r\n",
    "                    \r\n",
    "            if (rg <= 1 and rb <= 1 and gb <= 1):\r\n",
    "                images.append(head)\r\n",
    "    return images"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def find_useful_signs(directory):\r\n",
    "    \"\"\"Removes bad signs, such as those which are all white or all black\"\"\"\r\n",
    "    bw_images = find_bw_images(os.path.join(\"Traffic_Signs_Templates\", \"3_Damaged_Images\"))\r\n",
    "    for background_dir in load_paths(directory):\r\n",
    "        for background in load_paths(background_dir):\r\n",
    "            for signs in load_paths(background):\r\n",
    "                for dmgs in load_paths(signs):\r\n",
    "                    temp = []\r\n",
    "                    for imgs in load_paths(dmgs):\r\n",
    "                        temp.append(imgs)\r\n",
    "                    exposures = find_image_exposure(temp,4)\r\n",
    "                    \r\n",
    "                    ii = 0\r\n",
    "                    for images in load_paths(dmgs):\r\n",
    "                        #Find brightness\r\n",
    "                        img = Image.open(images).convert('RGBA')\r\n",
    "\r\n",
    "                        rgb = avrg_pixel_rgb(img,4)\r\n",
    "                        rg = abs(rgb[0] - rgb[1])\r\n",
    "                        rb = abs(rgb[0] - rgb[2])\r\n",
    "                        gb = abs(rgb[1] - rgb[2])\r\n",
    "\r\n",
    "                        is_bw = False\r\n",
    "\r\n",
    "                        for s in bw_images:\r\n",
    "                            if s in exposures[ii][0]:\r\n",
    "                                is_bw = True\r\n",
    "\r\n",
    "                        if (rg <= 16 and rb <= 16 and gb <= 16):\r\n",
    "                            if (not is_bw):\r\n",
    "                                os.remove(images)\r\n",
    "                            #Threshold values for black and white images\r\n",
    "                            elif (rgb[0] < 70 and rgb[1] < 70 and rgb[2] < 70):\r\n",
    "                                os.remove(images)\r\n",
    "                            elif (rgb[0] > 155 and rgb[1] > 155 and rgb[2] > 155):\r\n",
    "                                os.remove(images)\r\n",
    "\r\n",
    "                        elif (not is_bw):\r\n",
    "                            #Delete light blue images\r\n",
    "                            if(rgb[2] > rgb[0] and rgb[2] >= rgb[1]):\r\n",
    "                                if (gb <= 10):\r\n",
    "                                    os.remove(images)\r\n",
    "                    ii += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if original is True:\r\n",
    "    directory = \"Traffic_Signs_Exposure_Manipulation\"\r\n",
    "    find_useful_signs(directory)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def insert_poisson_noise (image):\r\n",
    "    vals = len(np.unique(image))\r\n",
    "    vals = 2.05 ** np.ceil(np.log2(vals))\r\n",
    "    noisy = np.random.poisson(image * vals) / float(vals)\r\n",
    "    return noisy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def insert_Gaussian_noise (image):\r\n",
    "    row,col,ch= image.shape\r\n",
    "    mean = 0\r\n",
    "    var = 0.5\r\n",
    "    sigma = var**0.5\r\n",
    "    gauss = np.random.normal(mean,sigma,(row,col,ch))\r\n",
    "    gauss = gauss.reshape(row,col,ch)\r\n",
    "    noisy = image + gauss\r\n",
    "    return noisy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def insert_speckle_noise (image):\r\n",
    "    row,col,ch = image.shape\r\n",
    "    gauss = np.random.randn(row,col,ch)\r\n",
    "    gauss = gauss.reshape(row,col,ch)        \r\n",
    "    noisy = image + image * gauss\r\n",
    "    return noisy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def random_noise_method (image):\r\n",
    "    \"\"\"\r\n",
    "    i = random.randint(1, 3)\r\n",
    "    if (i == 1):\r\n",
    "        return insert_poisson_noise(image)\r\n",
    "    elif (i==2):\r\n",
    "        return insert_Gaussian_noise(image)\r\n",
    "    else:\r\n",
    "        return insert_speckle_noise(image)\r\n",
    "    \"\"\"\r\n",
    "    image.setflags(write=1)\r\n",
    "    # Add noise in every pixel with random probability 0.4\r\n",
    "    for im in image:\r\n",
    "        px = 0\r\n",
    "        for pixel in im:\r\n",
    "            apply_noise = random.randint(0,100)\r\n",
    "            if apply_noise > 40:\r\n",
    "                # RGB values\r\n",
    "                r = pixel[0]\r\n",
    "                g = pixel[1]\r\n",
    "                b = pixel[2]\r\n",
    "                a = pixel[3]\r\n",
    "                # Find current relative lumination for brighness\r\n",
    "                # Based on: https://en.wikipedia.org/wiki/Relative_luminance\r\n",
    "                relative_lumination = 0.2126*r + 0.7152*g + 0.0722*b\r\n",
    "                # Find differences between RGB values     \r\n",
    "                rg = False\r\n",
    "                r_to_g = float(r) / float(g)\r\n",
    "                if (r_to_g >= 1):\r\n",
    "                    rg = True\r\n",
    "                \r\n",
    "                rb = False\r\n",
    "                r_to_b = float(r) / float(b)\r\n",
    "                if (r_to_b >= 1):\r\n",
    "                    rb = True\r\n",
    "                \r\n",
    "                gb = False\r\n",
    "                g_to_b = float(g) / float(b)\r\n",
    "                if (g_to_b >= 1):\r\n",
    "                    gb = True\r\n",
    "                \r\n",
    "                equal = False\r\n",
    "                if (r == g == b):\r\n",
    "                    equal = True\r\n",
    "\r\n",
    "                # In order to determine the margin in which the new brighness\r\n",
    "                # should be within, the upper and lower limits need to be found\r\n",
    "                # The Relative luminance in colorimetric spaces has normalised\r\n",
    "                # values between 0 and 255\r\n",
    "                upper_limit = 255\r\n",
    "                lower_limit = 0\r\n",
    "                if (relative_lumination + 40 < 255):\r\n",
    "                    upper_limit = relative_lumination + 40\r\n",
    "                if (relative_lumination - 40 > 0):\r\n",
    "                    lower_limit = relative_lumination - 40\r\n",
    "\r\n",
    "                # Compute new brightness value\r\n",
    "                new_lumination = random.randint(int(lower_limit), int(upper_limit))\r\n",
    "\r\n",
    "                # Find the three possible solutions that satisfy\r\n",
    "                # -> The new lumination chosen based on the Relative luminance equation\r\n",
    "                # -> The precentages computed between every rgb value\r\n",
    "\r\n",
    "                solutions = []\r\n",
    "\r\n",
    "                for r in range(1,255):\r\n",
    "                    for g in range(1,255):\r\n",
    "                        for b in range(1,255):\r\n",
    "                            rg = False\r\n",
    "                            r_to_g = float(r) / float(g)\r\n",
    "                            if (r_to_g >= 1):\r\n",
    "                                rg = True\r\n",
    "                            \r\n",
    "                            rb = False\r\n",
    "                            r_to_b = float(r) / float(b)\r\n",
    "                            if (r_to_b >= 1):\r\n",
    "                                rb = True\r\n",
    "                            \r\n",
    "                            gb = False\r\n",
    "                            g_to_b = float(g) / float(b)\r\n",
    "                            if (g_to_b >= 1):\r\n",
    "                                gb = True\r\n",
    "                            \r\n",
    "                            e = False\r\n",
    "                            if(r == g == b):\r\n",
    "                                e = True\r\n",
    "                            \r\n",
    "                            if (0.2126*r + 0.7152*g + 0.0722*b == 100) and rg==rg and rb==rb and gb==GB and e==equal:\r\n",
    "                                solutions.append([r,g,b])\r\n",
    "\r\n",
    "                # Find the solution that precentage wise is closer to the original\r\n",
    "                # difference between the values\r\n",
    "                percentages = []\r\n",
    "\r\n",
    "                for solution in solutions:\r\n",
    "                    r = solution[0]\r\n",
    "                    g = solution[1]\r\n",
    "                    b = solution[2]\r\n",
    "                    percentages.append((float(r) / float(g)) + (float(r) / float(b)) + (float(g) / float(b)))\r\n",
    "\r\n",
    "                ii = 0\r\n",
    "                pos = 0\r\n",
    "                best = percentages[0]\r\n",
    "                for p in percentages[1:]:\r\n",
    "                    if p < best:\r\n",
    "                        pos = ii\r\n",
    "                    ii += 1\r\n",
    "\r\n",
    "                # Assign new pixel values\r\n",
    "                im[px] = [solutions[pos][0], solutions[pos][1], solutions[pos][2], A]\r\n",
    "            px += 1\r\n",
    "            \r\n",
    "    return image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def has_opaque_pixel(line):\r\n",
    "    \"\"\"Checks if a line of pixels contains a pixel above a transparency threshold\"\"\"\r\n",
    "    opaque = False\r\n",
    "    for pixel in line:\r\n",
    "        # Check if pixel is opaque\r\n",
    "        if pixel[3] > 200:\r\n",
    "            opaque = True\r\n",
    "            break  # Stop searching if one is found\r\n",
    "    return opaque\r\n",
    "\r\n",
    "def bounding_axes(img):\r\n",
    "    \"\"\"Returns the bounding axes of an image with a transparent background\"\"\"\r\n",
    "    # Top axis\r\n",
    "    y_top = 0\r\n",
    "    for row in img:  # Iterate through each row of pixels, starting at top-left\r\n",
    "        if has_opaque_pixel(row) is False:  # Check if the row has an opaque pixel\r\n",
    "            y_top += 1  # If not, move to the next row\r\n",
    "        else:\r\n",
    "            break  # If so, break, leaving y_top as the bounding axis\r\n",
    "\r\n",
    "    # Bottom axis\r\n",
    "    height = img.shape[0]\r\n",
    "    y_bottom = height - 1\r\n",
    "    for row in reversed(img):  # Iterate from the bottom row up\r\n",
    "        if has_opaque_pixel(row) is False:\r\n",
    "            y_bottom -= 1\r\n",
    "        else:\r\n",
    "            break\r\n",
    "\r\n",
    "    # Left axis\r\n",
    "    # Rotate 90 degrees to iterate through what were originally columns\r\n",
    "    r_img = imutils.rotate_bound(img, 90)\r\n",
    "    x_left = 0\r\n",
    "    for column in r_img:\r\n",
    "        if has_opaque_pixel(column) is False:\r\n",
    "            x_left += 1\r\n",
    "        else:\r\n",
    "            break\r\n",
    "\r\n",
    "    # Right axis\r\n",
    "    r_height = r_img.shape[0]\r\n",
    "    x_right = r_height - 1\r\n",
    "    for column in reversed(r_img):\r\n",
    "        if has_opaque_pixel(column) is False:\r\n",
    "            x_right -= 1\r\n",
    "        else:\r\n",
    "            break\r\n",
    "\r\n",
    "    # FOR TESTING\r\n",
    "    # img[y_top, :] = (255, 0, 0, 255)\r\n",
    "    # img[y_bottom, :] = (255, 0, 0, 255)\r\n",
    "    # img[:, x_left] = (255, 0, 0, 255)\r\n",
    "    # img[:, x_right] = (255, 0, 0, 255)\r\n",
    "    # cv2.imwrite(image_dir, img)\r\n",
    "\r\n",
    "    return [x_left, x_right, y_top, y_bottom]\r\n",
    "\r\n",
    "# FOR TESTING\r\n",
    "# for img in load_paths(\"Traffic_Signs_Templates/4_Transformed_Images/0/0_ORIGINAL\"):\r\n",
    "#     bounding_axes(img)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### FULL BACKGROUND ###\r\n",
    "def new_data(image_dir, bg_dir, label_file, filename, values):\r\n",
    "    \"\"\"Blends synthetic signs with backgrounds\"\"\"\r\n",
    "    bg = cv2.imread(bg_dir, cv2.IMREAD_UNCHANGED)\r\n",
    "    fg = cv2.imread(image_dir, cv2.IMREAD_UNCHANGED)\r\n",
    "    bg_height, bg_width, _ = bg.shape\r\n",
    "    fg_height, fg_width, _ = fg.shape\r\n",
    "\r\n",
    "    # Rescaling the sign to correct its size relative to the background\r\n",
    "    # NOTE: Assumes background aspect ratio somewhat close to 16:9 (1.778)\r\n",
    "    current_ratio = fg_width / bg_width # Ratio of sign width to the background width\r\n",
    "    target_ratio = random.uniform(0.033, 0.066) # Aiming for between 3.3% and 6.6% of bg width\r\n",
    "    scale_factor = target_ratio / current_ratio\r\n",
    "    new_size = int(fg_width * scale_factor)\r\n",
    "    fg = cv2.resize(fg, (new_size, new_size))\r\n",
    "\r\n",
    "    # Randomise sign placement within middle third of background\r\n",
    "    x = random.randint(0, bg_width - fg_width)\r\n",
    "    third = bg_height // 3\r\n",
    "    y = random.randint(third, bg_height - third)\r\n",
    "\r\n",
    "    # Build label\r\n",
    "    axes = bounding_axes(fg)  # Retrieve bounding axes of the sign image\r\n",
    "    axes[0] += x  # Adjusting bounding axis to make it relative to the whole bg image\r\n",
    "    axes[1] += x\r\n",
    "    axes[2] += y\r\n",
    "    axes[3] += y\r\n",
    "    bounds = str(axes[0]) + \" \" + str(axes[1]) + \" \" + str(axes[2]) + \" \" + str(axes[3])\r\n",
    "\r\n",
    "    # It is assumed that the final .jpg -> .png conversion step is executed\r\n",
    "    label = filename + \".jpg \" + bounds + \" \" + values + \"\\n\"\r\n",
    "    label_file.write(label)\r\n",
    "    image = overlay(fg, bg, x, y)\r\n",
    "\r\n",
    "    return image\r\n",
    "\r\n",
    "\r\n",
    "### ORIGINAL ### (Outdated - used for creating classification data)\r\n",
    "# def new_data(image_dir,bg_dir): #Blends synthetic signs with backgrounds\r\n",
    "#     # Import background image\r\n",
    "#     background_img_raw = Image.open(bg_dir).convert('RGBA')  \r\n",
    "#     background_img_raw = background_img_raw.resize((150,150), Image.ANTIALIAS)\r\n",
    "#     background_img = np.array(background_img_raw)  \r\n",
    "#     background_img_float = background_img.astype(float)  \r\n",
    "\r\n",
    "#     # Import foreground image\r\n",
    "#     foreground_img_raw = Image.open(image_dir)  \r\n",
    "#     foreground_img = np.array(foreground_img_raw)  \r\n",
    "#     foreground_img_float = foreground_img.astype(float)  \r\n",
    "\r\n",
    "#     # Blend images\r\n",
    "#     opacity = 1  \r\n",
    "#     blended_img_float = blend_modes.grain_merge(background_img_float, foreground_img_float, opacity)\r\n",
    "\r\n",
    "#     # Convert blended image back into PIL image\r\n",
    "#     blended_img = np.uint8(blended_img_float)\r\n",
    "#     blended_img_raw = Image.fromarray(blended_img)  \r\n",
    "    \r\n",
    "#     foreground_img_raw = foreground_img_raw.resize((149,149), Image.ANTIALIAS)\r\n",
    "#     blended_img_raw.paste(foreground_img_raw, (0, 0), foreground_img_raw)\r\n",
    "#     blended_img_raw = blended_img_raw.resize((48,48), Image.ANTIALIAS)\r\n",
    "    \r\n",
    "#     # temp = np.uint8(blended_img_raw)\r\n",
    "#     # temp = random_noise_method(temp)\r\n",
    "    \r\n",
    "#     # blended_img_raw = Image.fromarray(np.uint8(temp)) \r\n",
    "    \r\n",
    "#     return blended_img_raw"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create the required directories in SGTSD\r\n",
    "if (not os.path.exists(\"SGTSD/Images\")):\r\n",
    "    # Numbered Version\r\n",
    "    for sign in load_paths(os.path.join(\"Traffic_Signs_Templates\", \"1_Input_Images\")):  # Dir. for each sign type\r\n",
    "        head, tail = sign.split('.')\r\n",
    "        name = dir_split(head)\r\n",
    "        os.makedirs(os.path.join(\"SGTSD\", \"Images\", name[-1]))\r\n",
    "        j = 0\r\n",
    "        for dmg in range(len(damage_types)):  # Dir. for each damage type\r\n",
    "            os.makedirs(os.path.join(\"SGTSD\", \"Images\", name[-1], name[-1] + \"_\" + str(j)))\r\n",
    "            j = j + 1\r\n",
    "    \r\n",
    "    # Named Version (Outdated?)\r\n",
    "#     for sign in load_paths(os.path.join(\"Traffic_Signs_Templates\", \"1_Input_Images\")):  # Dir. for each sign type\r\n",
    "#         head, tail = sign.split('.')\r\n",
    "#         name = dir_split(head)\r\n",
    "#         os.makedirs(os.path.join(\"SGTSD\", \"Images\", name[-1]))\r\n",
    "#         for dmg in load_paths(os.path.join(\"Traffic_Signs_Templates\", \"3_Damaged_Images\")): #Dir. for each damage type\r\n",
    "#             headD,tailD = dmg.split('.')\r\n",
    "#             nameD = dir_split(headD)\r\n",
    "#             os.makedirs(os.path.join(\"SGTSD\", \"Images\", name[-1], nameD[-1]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a README file\r\n",
    "content = '''\r\n",
    "-----------------------------------------------\r\n",
    "|                     -*-                     |\r\n",
    "|Synthetically Generated Traffic Sign Dataset |\r\n",
    "|                     -*-                     |\r\n",
    "-----------------------------------------------\r\n",
    "\r\n",
    "This directory contains the generated training\r\n",
    "set to be used for training a Convolutional\r\n",
    "Neural Network (CNN).\r\n",
    "\r\n",
    "It may be used for any detector desired and it\r\n",
    "is not limited to a specific set of traffic\r\n",
    "sign templates.\r\n",
    " \r\n",
    "\r\n",
    "----------------------------------------------\r\n",
    "Content\r\n",
    "----------------------------------------------\r\n",
    "\r\n",
    "The number of examples is based on the number:\r\n",
    "->of traffic signs that were used as templates\r\n",
    "->of damage types applied to images\r\n",
    "->of transformations in image manipulations\r\n",
    "->of the brightness variation values used\r\n",
    "->of blending procedures\r\n",
    "\r\n",
    "\r\n",
    "----------------------------------------------\r\n",
    "Image format and naming\r\n",
    "----------------------------------------------\r\n",
    "\r\n",
    "The images created are of \"jpg\" format\r\n",
    "with RGBA channels.\r\n",
    "\r\n",
    "   XXX/XXX_YYY/XXX_YYY_ZZZ.jpg\r\n",
    "\r\n",
    "(X) is used to distinguish the sign class, (Y)\r\n",
    "is used to distinguish the damage type and (Z)\r\n",
    "is used to indicate the example number.\r\n",
    "\r\n",
    "\r\n",
    "----------------------------------------------\r\n",
    "Additional information\r\n",
    "----------------------------------------------\r\n",
    "\r\n",
    "Contact Email:\r\n",
    "   Original Code:\r\n",
    "\t   asterga@essex.ac.uk\r\n",
    "\r\n",
    "   Adapted Damage Code:\r\n",
    "      kristian.rados@student.curtin.edu.au\r\n",
    "      seana.dale@student.curtin.edu.au\r\n",
    "\r\n",
    "\r\n",
    "----------------------------------------------\r\n",
    "'''\r\n",
    "\r\n",
    "text_file = open(\"SGTSD/Readme_Images.txt\", \"w\")\r\n",
    "text_file.write(content)\r\n",
    "text_file.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# List of paths for all SGTSD relevant files using exposure_manipulation\r\n",
    "def create_paths_list(imgs_directory, bg_directory):\r\n",
    "    directories = []\r\n",
    "    for places in load_paths(imgs_directory):  # List of places: originally either UK_rural or UK_urban\r\n",
    "        for imgs in load_paths(places):  # Folder for each bg image: eg. IMG_0\r\n",
    "            dr = dir_split(imgs)\r\n",
    "            bg = os.path.join(bg_directory, dr[-2], dr[-1] + \".png\")  # Retrieving relevant bg image\r\n",
    "            for signs in load_paths(imgs):  # Folder for each sign type: eg. SIGN_9\r\n",
    "                for dmgs in load_paths(signs):  # Folder for each damage type: eg. 0_HOLES\r\n",
    "                    for png in load_paths(dmgs):\r\n",
    "                        directories.append([png, bg])\r\n",
    "    return directories  # Directory for every single FILE and it's relevant bg FILE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# List of paths for all SGTSD relevant files using fade_manipulation; backgrounds are assigned to \r\n",
    "def create_assigned_paths_list(imgs_directory, bg_directory): #TODO: is this the same as above?\r\n",
    "    directories = []\r\n",
    "    for places in load_paths(bg_directory):  # Folder for each place: eg. GTSDB\r\n",
    "        for imgs in load_paths(places):  # Iterate through each b.g. image: eg. IMG_0\r\n",
    "            for signs in load_paths(imgs_directory):  # Folder for each sign type: eg. SIGN_9\r\n",
    "                for dmgs in load_paths(signs):  # Folder for each damage type: eg. 9_HOLES\r\n",
    "                    for png in load_paths(dmgs):\r\n",
    "                        directories.append([png, imgs])\r\n",
    "    return directories  # Directory for every single FILE and its relevant bg FILE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if original is True:\r\n",
    "    directories = create_paths_list(\"Traffic_Signs_Exposure_Manipulation\", \"Backgrounds\")\r\n",
    "else:\r\n",
    "    directories = create_assigned_paths_list(\"Traffic_Signs_Fade_Manipulation\", \"Backgrounds\")\r\n",
    "print(\"Files to be generated: \" + str(len(directories)))"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true,
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Paths of images needed to generate examples for 'sign' with damage 'dmg'\r\n",
    "def list_for_sign_x(sign, dmg, directories):\r\n",
    "    l = []\r\n",
    "    for elements in directories:\r\n",
    "        foreground = dir_split(elements[0])\r\n",
    "        if (foreground[-2] == sign + dmg):  # Eg. if (9_YELLOW == 4_ORIGINAL)\r\n",
    "            l.append(elements)\r\n",
    "    return l  # Directory for every single sign and its relevant background image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#TODO: Something has gone wrong here onwards... final_directories is filled with empty elements"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_directories = []  # Reformat list to have each sign and damage as their own dimensions\r\n",
    "signs = load_paths(os.path.join(\"Traffic_Signs_Templates\", \"1_Input_Images\"))\r\n",
    "for i in signs:\r\n",
    "    head, tail = ntpath.split(i)\r\n",
    "    sign, extension = tail.split('.')  # Eg. sign == \"9\"\r\n",
    "\r\n",
    "    sign_list = []  # List of damages, which are each list of signs\r\n",
    "    for dmg in damage_types:  # Damage_types is from 'def damage_images:' cell\r\n",
    "        sign_list.append(list_for_sign_x(sign, dmg, directories))\r\n",
    "    final_directories.append(sign_list)  # List of types -> lists of damages -> lists of signs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate and write the new data to its file\r\n",
    "direct = os.path.join(\"SGTSD\", \"Images\")\r\n",
    "direct1 = os.path.join(\"SGTSD\", \"Labels\")\r\n",
    "folders = load_paths(direct)\r\n",
    "n = []  # Numbers from the folder names for the signs\r\n",
    "for folder in folders:\r\n",
    "    head, tail = ntpath.split(folder)\r\n",
    "    n.append(tail)\r\n",
    "\r\n",
    "# Count how many signs there are; needed for the progress bar\r\n",
    "total = 0\r\n",
    "for signs in final_directories:\r\n",
    "    for damages in signs:\r\n",
    "        for dirs in damages:\r\n",
    "            total += 1\r\n",
    "\r\n",
    "count = 0\r\n",
    "ii = 0\r\n",
    "for signs in final_directories:  # Iterate through sign types\r\n",
    "    jj = 0\r\n",
    "    for damages in signs:  # Iterate through damage types\r\n",
    "        # FIXME: For some reason secondary progress counter has broken from initial implementation\r\n",
    "        print(\"Processed: \" + str(float(count) / float(total) * 100) + \" %\")\r\n",
    "        kk = 0\r\n",
    "\r\n",
    "        label_filename = os.path.join(direct1, n[ii], n[ii] + \"_\" + str(ij) + \".txt\")\r\n",
    "        text_file = open(label_filename, \"r\")\r\n",
    "        values = text_file.read()  # Retrieve the damage values created earlier in the damage_images function\r\n",
    "        text_file = open(label_filename, \"w\")\r\n",
    "\r\n",
    "        for dirs in damages:  # dirs == the foreground and background images for one generated sign\r\n",
    "            filename = os.path.join(direct, n[ii], n[ii] + \"_\" + str(ij), n[ii] + \"_\" + str(ij) + \"_\" + str(kk))\r\n",
    "            image = new_data(dirs[0], dirs[1], text_file, filename, values) # Combining b.g. with sign f.g.\r\n",
    "            cv2.imwrite(filename + \".png\", image)\r\n",
    "\r\n",
    "            count += 1\r\n",
    "            kk += 1\r\n",
    "        jj += 1\r\n",
    "        text_file.close()\r\n",
    "    ii += 1\r\n",
    "print(\"Processed: \" + str(100) + \" %\")  # FIXME: changing damage names broke something"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "string = '''\n",
    "-------------------------------------\n",
    "BREAKDOWN OF FILES GENERATED BY CLASS\n",
    "-------------------------------------\n",
    "'''\n",
    "total = 0\n",
    "for i in range(len(final_directories)):\n",
    "    current = 0\n",
    "    for j in range(len(final_directories[i])):\n",
    "        current = current + len(final_directories[i][j])\n",
    "    s = \"Generated \" + str(current) + \" examples for sign class \" + str(i + 1)\n",
    "    string = string + '\\n' + s + '\\n'\n",
    "    total = total + current\n",
    "string = string + '\\n' + \"TOTAL: \" + str(total) + '\\n' + \"Generated on: \" + datetime.now().strftime(\"%Y-%m-%d %H:%M\") + '\\n'\n",
    "string = string + \"-------------------------------------\"\n",
    "text_file = open(os.path.join(\"SGTSD\", \"generated_images_about.txt\"), \"w\")\n",
    "text_file.write(string)\n",
    "text_file.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def png_to_jpeg(filepath):\n",
    "    sep = os.sep\n",
    "\n",
    "    dirs = dir_split(filepath)\n",
    "    title,extension = dirs[-1].split('.')\n",
    "    del dirs[-1]\n",
    "    string = sep.join(dirs)\n",
    "    string = os.path.join(string, title + \".jpg\")\n",
    "    png = Image.open(filepath)\n",
    "    png.load()  # Required for png.split()\n",
    "    background = Image.new(\"RGB\", png.size, (255, 255, 255))\n",
    "    background.paste(png, mask=png.split()[3])  # 3 is the alpha channel\n",
    "    background.save(string, 'JPEG', quality=100)\n",
    "    os.remove(filepath)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dirs = direct = os.path.join(\"SGTSD\", \"Images\")\n",
    "i = 1\n",
    "for path in load_paths(dirs):\n",
    "    print(\"Processed: \" + str(float(i - 1) / float(len(final_directories)) * 100) + \" %\")\n",
    "    for damage in load_paths(path):\n",
    "        for image in load_paths(damage):\n",
    "            if (image.endswith(\"png\")):\n",
    "                png_to_jpeg(image)\n",
    "    i += 1\n",
    "print(\"Processed: \" + str(100) + \" %\")"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# shutil.rmtree(\"Traffic_Signs_Exposure_Manipulation\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# shutil.rmtree(\"Traffic_Signs_Fade_Manipulation\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# shutil.rmtree(\"Traffic_Signs_Templates/4_Transformed_Images\")\n",
    "# shutil.rmtree(\"Traffic_Signs_Templates/3_Damaged_Images\")\n",
    "# shutil.rmtree(\"Traffic_Signs_Templates/2_Processed_Images\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# shutil.rmtree(\"SGTSD\")  # Be careful with this one"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "44edcd40e284cf5cfda50548e680aee2d495489cee3c07a66e76ab385d306a84"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}